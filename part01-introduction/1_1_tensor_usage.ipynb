{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 关于 Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tensor的数据类型\n",
    "\n",
    "###  32位浮点型：torch.FloatTensor (Tensor默认的数据类型)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = torch.Tensor( [[2,3],[4,8],[7,9]], )\n",
    "print(a)\n",
    "print('size:', a.size())\n",
    "print('dtype:', a.dtype)\n",
    "\n",
    "b=torch.FloatTensor( [[2,3],[4,8],[7,9]] )\n",
    "print(b)\n",
    "print('size:', b.size())\n",
    "print('dtype:', b.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 64位浮点型：torch.DoubleTensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# b = torch.DoubleTensor( [[2,3],[4,8],[7,9]] )\n",
    "b = torch.Tensor( [True, True, False])\n",
    "print(b)\n",
    "print('size:', b.size(), 'dtype:', b.dtype)\n",
    "size = b.size()\n",
    "c = size[0]\n",
    "print(c)\n",
    "for i,t in enumerate(b):\n",
    "    print(i, t )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 16位整型：torch.ShortTensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "b=torch.ShortTensor( [[2,3],[4,8],[7,9]] )\n",
    "print(b)\n",
    "print('size:', b.size(), 'dtype:', b.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 32位整型：torch.IntTensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "b=torch.IntTensor( [[2,3],[4,8],[7,9]] )\n",
    "print(b)\n",
    "print('size:', b.size(), 'dtype:', b.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 64位整型：torch.LongTensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "b=torch.LongTensor( [[2,3],[4,8],[7,9]] )\n",
    "print(b)\n",
    "print('size:', b.size(), 'dtype:', b.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 布尔类型：torch.BoolTensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "b = torch.BoolTensor( [True, True, False])\n",
    "print(b.int())\n",
    "print(b)\n",
    "print('size:', b.size(), 'dtype:', b.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n = np.array([])\n",
    "a = torch.FloatTensor([1,2,3.2])\n",
    "print(a)\n",
    "print(a[0].numpy())\n",
    "c = np.append(b,0)\n",
    "print(c[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  类型转换\n",
    "\n",
    "1. 数据类型转换\n",
    "    * 在Tensor后加 .long(), .int(), .float(), .double()等即可，也可以用.to()函数进行转换，所有的Tensor类型可参考https://pytorch.org/docs/stable/tensors.html\n",
    "2. 数据存储位置转换\n",
    "    * CPU张量 ---->  GPU张量，使用data.cuda()\n",
    "    * GPU张量 ----> CPU张量，使用data.cpu()\n",
    "3. 与numpy数据类型转换\n",
    "    * Tensor---->Numpy  使用 data.numpy()，data为Tensor变量\n",
    "    * Numpy ----> Tensor 使用 torch.from_numpy(data)，data为numpy变量\n",
    "4. 与Python数据类型转换\n",
    "    * Tensor ----> 单个Python数据，使用data.item()，data为Tensor变量且只能为包含单个数据\n",
    "    * Tensor ----> Python list，使用data.tolist()，data为Tensor变量，返回shape相同的可嵌套的list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 更改Tensor的数据类型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a=torch.FloatTensor( (3,2) )\n",
    "print(a)\n",
    "print('size:', a.size(), 'dtype:', a.dtype)\n",
    "\n",
    "b= a.int()\n",
    "print(b)\n",
    "print('size:', b.size(), 'dtype:', b.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tensor和numpy数组转换"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = torch.randn( size=(4,5),dtype=torch.float32 ) # Tensor转numpy\n",
    "print(a)\n",
    "print('size:', a.size(), 'dtype:', a.dtype)\n",
    "\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "print('size:', b.shape, 'dtype:', b.dtype)\n",
    "\n",
    "c = np.random.randn(3,4) # numpy转Tensor\n",
    "print(c)\n",
    "print('size:', c.shape, 'dtype:', c.dtype)\n",
    "\n",
    "d=torch.from_numpy( c )\n",
    "print(d)\n",
    "print('size:', d.size(), 'dtype:', d.dtype)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tensor和 python数据类型的转换"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = torch.randn( size=(4,5),dtype=torch.float32 ) # Tensor转numpy\n",
    "print('size:', a.size(), 'dtype:', a.dtype)\n",
    "b = a.tolist()\n",
    "print(b)\n",
    "print('type:', type(b))\n",
    "\n",
    "a = torch.randn( size=(4,1),dtype=torch.float32 ) # Tensor转numpy\n",
    "print(a)\n",
    "print('size:', a.size(), 'dtype:', a.dtype)\n",
    "b = a[0].item()\n",
    "print(b)\n",
    "print('type:', type(b))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 快速创建Tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 特殊tensor\n",
    "* torch.zeros\n",
    "* torch.ones\n",
    "* torch.arange 根据start与stop指定的范围以及step设定的步长，生成一个array"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. 全为0 a\n",
    "t=torch.zeros( size=(4,5),dtype=torch.float32 )\n",
    "print('全为0 ',t)\n",
    "print('size:', t.size(), 'dtype:', t.dtype)\n",
    "print('全为1 ', torch.ones(size=(3,4)))\n",
    "print('顺序 ', torch.arange(1,11))\n",
    "print('步长0.1 ', torch.arange(1,2,0.1))\n",
    "print('步长-0.1 ', torch.arange(1,0, -0.1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 生成随机数Tensor的方法\n",
    " * torch.rand() 均匀分布, 从区间[0, 1)的均匀分布中抽取的一组随机数\n",
    " * torch.randn() 标准正态分布, 从标准正态分布（均值为0，方差为1，即高斯白噪声）中抽取的一组随机数\n",
    " * torch.normal(means, std, out=None) → Tensor 离散正态分布,从指定均值means和标准差std的离散正态分布中抽取的一组随机数\n",
    " * ttorch.linspace(start, end, steps=100, out=None) → Tensor 线性间距向量, 在区间start和end上均匀间隔的step个点"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = torch.rand(size=(4,5))\n",
    "print(t)\n",
    "print('size:', t.size(), 'dtype:', t.dtype)\n",
    "t = torch.randn(2, 3)\n",
    "print(t)\n",
    "\n",
    "t = torch.normal(mean=torch.full([10],0.), std=torch.arange(1, 0.0,-0.1))\n",
    "print(t)\n",
    "t = torch.linspace(3, 10, steps=5)\n",
    "print(t)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tensor的比较\n",
    "> Tensor本身就可以进行一些比较, 更详细的资料大家可以去阅读官方文档。\n",
    "\n",
    "* 等于 torch.equal(tensor1, tensor2) → bool\n",
    "    > 如果两个张量的尺寸和元素都相同，则返回True，否则返回False。\n",
    "* 大于 torch.gt(input, other, out=None) → Tensor\n",
    "* 大于等于 torch.ge(input, other, out=None) → Tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(torch.equal(torch.Tensor([1, 2]), torch.Tensor([1, 2])))\n",
    "print(torch.gt(torch.Tensor([1, 2]), torch.Tensor([1, 2])))\n",
    "# print(torch.gt(torch.Tensor([1, 2, 3]), torch.Tensor([1, 2]))) RuntimeError:  size 要一致\n",
    "print(torch.gt(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]])))\n",
    "print(torch.gte(torch.Tensor([1, 2]), torch.Tensor([1, 2])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}